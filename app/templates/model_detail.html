{% extends "base.html" %}

{% block title %}Model · Orchestrator{% endblock %}

{% block content %}
<section class="card">
  {% if is_new %}
    <h2>Neues Model</h2>
  {% else %}
    <h2>Model: {{ model.id }}</h2>
  {% endif %}

  {% if error %}
    <p class="warning">{{ error }}</p>
  {% endif %}
  {% if notice %}
    <p class="hint">{{ notice }}</p>
  {% endif %}

  <form method="post" action="{% if is_new %}/ui/models{% else %}/ui/models/{{ model.id }}{% endif %}" class="stack">
    <label>
      Model ID
      {% if is_new %}
        <input type="text" name="model_id" value="{{ model.id }}" required />
      {% else %}
        <input type="text" name="model_id" value="{{ model.id }}" readonly />
      {% endif %}
    </label>
    <label>
      Role
      <select name="role" required>
        <option value="" {% if not model.role %}selected{% endif %}>Bitte wählen</option>
        {% for role in roles %}
          <option value="{{ role }}" {% if model.role == role %}selected{% endif %}>{{ role }}</option>
        {% endfor %}
      </select>
    </label>
    {% if model.role %}
      {% set suggestions = models_by_role.get(model.role) or [] %}
      {% if suggestions %}
        <p class="hint">Vorhandene Modelle für {{ model.role }}: {{ suggestions | join(", ") }}</p>
      {% endif %}
    {% endif %}
    <label>
      Provider
      <input type="text" name="provider" value="{{ model.provider or "" }}" required />
    </label>
    <label>
      Model Name
      <input type="text" name="model_name" value="{{ model.model_name or "" }}" list="vllm-models" required />
    </label>
    <div class="stack">
      <button
        type="button"
        class="button"
        hx-get="/ui/models/discover/openai_models"
        hx-include="[name='base_url']"
        hx-target="#vllm-models-container"
        hx-swap="innerHTML"
      >
        Modelle abrufen (llama.cpp · OpenAI-compat)
      </button>
      <button
        type="button"
        class="button"
        hx-get="/ui/models/discover/openai_test"
        hx-include="[name='base_url']"
        hx-target="#vllm-connection-status"
        hx-swap="innerHTML"
      >
        Test connection (llama.cpp · OpenAI-compat)
      </button>
      <div id="vllm-connection-status"></div>
      <div id="vllm-models-container">
        <datalist id="vllm-models"></datalist>
      </div>
    </div>
    <div class="stack">
      <button type="button" class="button" id="llamacpp-start">
        Start llama-server
      </button>
      <button type="button" class="button" id="llamacpp-stop">
        Stop llama-server
      </button>
      <button type="button" class="button" id="llamacpp-use-endpoint">
        Use running endpoint as base_url
      </button>
      <input type="hidden" name="runtime_instance_id" id="llamacpp-instance-id" />
      <div id="llamacpp-runtime-status" class="hint"></div>
    </div>
    <label>
      Base URL
      <input type="text" name="base_url" value="{{ model.base_url or "" }}" required />
    </label>
    <label>
      Model Path (optional, local GGUF)
      <input
        type="text"
        name="model_path"
        value="{{ model.model_path or "" }}"
        list="local-gguf-models"
      />
    </label>
    <div class="stack">
      <button
        type="button"
        class="button"
        hx-get="/ui/models/discover/local_gguf"
        hx-target="#local-gguf-models-container"
        hx-swap="innerHTML"
      >
        Lokale GGUFs vorschlagen
      </button>
      <div id="local-gguf-models-container">
        <datalist id="local-gguf-models"></datalist>
      </div>
    </div>
    <label>
      Prompt Profile
      <textarea name="prompt_profile" rows="6" required>{{ model.prompt_profile or "" }}</textarea>
    </label>
    <label>
      Adapter (optional metadata)
      <textarea name="adapter" rows="3" placeholder='{"notes": "..."}'>{{ model.adapter or "" }}</textarea>
    </label>

    {% if model.role == "validator" %}
      {% set config = model.validator_config or {} %}
      <fieldset class="stack">
        <legend>Validator Config</legend>
        <label>
          <input type="checkbox" name="validator_use_llm" {% if config.use_llm %}checked{% endif %} />
          Use LLM runtime
        </label>
        <label>
          Max Attempts
          <input type="number" name="validator_max_attempts" min="0" value="{{ config.max_attempts or "" }}" />
        </label>
        <label>
          Compression Token Budget
          <input type="number" name="validator_compression_token_budget" min="0" value="{{ config.compression_token_budget or "" }}" />
        </label>
        <label>
          Stop Conditions (one per line)
          <textarea name="validator_stop_conditions" rows="3">{{ config.stop_conditions | join('\n') if config.stop_conditions else "" }}</textarea>
        </label>
        <label>
          Allowed Decisions (one per line)
          <textarea name="validator_allowed_decisions" rows="4">{{ config.allowed_decisions | join('\n') if config.allowed_decisions else "" }}</textarea>
        </label>
        <label>
          Allowed Retry Strategies (one per line)
          <textarea name="validator_allowed_retry_strategies" rows="4">{{ config.allowed_retry_strategies | join('\n') if config.allowed_retry_strategies else "" }}</textarea>
        </label>
        <label>
          Rubric Weights (JSON)
          <textarea name="validator_rubric_weights" rows="3" placeholder='{"correctness": 0.4}'>{{ config.rubric_weights | tojson if config.rubric_weights else "" }}</textarea>
        </label>
      </fieldset>
    {% endif %}

    <div class="actions">
      <button type="submit" class="primary">Speichern</button>
      <a class="button" href="/ui/models">Zurück</a>
    </div>
  </form>

  {% if not is_new %}
  <form method="post" action="/ui/models/{{ model.id }}/test" class="actions">
    <button type="submit" class="button">Dry-Run Test</button>
  </form>
  {% endif %}
</section>
<script>
  (() => {
    const startButton = document.getElementById("llamacpp-start");
    const stopButton = document.getElementById("llamacpp-stop");
    const useButton = document.getElementById("llamacpp-use-endpoint");
    const statusEl = document.getElementById("llamacpp-runtime-status");
    const instanceInput = document.getElementById("llamacpp-instance-id");
    const modelPathInput = document.querySelector("[name='model_path']");
    const roleInput = document.querySelector("[name='role']");
    const baseUrlInput = document.querySelector("[name='base_url']");

    const setStatus = (text, isError = false) => {
      statusEl.textContent = text;
      statusEl.classList.toggle("warning", isError);
      statusEl.classList.toggle("hint", !isError);
    };

    const fetchJson = async (url, options = {}) => {
      const response = await fetch(url, options);
      const payload = await response.json().catch(() => ({}));
      if (!response.ok) {
        const detail = payload.detail || response.statusText;
        throw new Error(detail);
      }
      return payload;
    };

    const getRunningInstance = (instances) => {
      const role = roleInput?.value;
      return (
        instances.find((entry) => entry.status === "running" && entry.role === role) ||
        instances.find((entry) => entry.status === "running")
      );
    };

    startButton?.addEventListener("click", async () => {
      if (!modelPathInput?.value) {
        setStatus("Bitte zuerst einen Model Path angeben.", true);
        return;
      }
      try {
        const payload = {
          model_path: modelPathInput.value,
          role: roleInput?.value,
        };
        const data = await fetchJson("/api/runtimes/llamacpp/start", {
          method: "POST",
          headers: {"Content-Type": "application/json"},
          body: JSON.stringify(payload),
        });
        instanceInput.value = data.id || "";
        statusEl.dataset.baseUrl = data.base_url || "";
        setStatus(`Gestartet auf ${data.base_url || "unknown"}.`);
      } catch (error) {
        setStatus(error.message, true);
      }
    });

    stopButton?.addEventListener("click", async () => {
      try {
        let instanceId = instanceInput.value;
        if (!instanceId) {
          const list = await fetchJson("/api/runtimes/llamacpp/list");
          const running = getRunningInstance(list.instances || []);
          instanceId = running?.id || "";
        }
        if (!instanceId) {
          setStatus("Keine laufende Instanz gefunden.", true);
          return;
        }
        await fetchJson("/api/runtimes/llamacpp/stop", {
          method: "POST",
          headers: {"Content-Type": "application/json"},
          body: JSON.stringify({instance_id: instanceId}),
        });
        instanceInput.value = "";
        statusEl.dataset.baseUrl = "";
        setStatus("Instanz gestoppt.");
      } catch (error) {
        setStatus(error.message, true);
      }
    });

    useButton?.addEventListener("click", async () => {
      try {
        let baseUrl = statusEl.dataset.baseUrl || "";
        if (!baseUrl) {
          const list = await fetchJson("/api/runtimes/llamacpp/list");
          const running = getRunningInstance(list.instances || []);
          baseUrl = running?.base_url || "";
          statusEl.dataset.baseUrl = baseUrl;
        }
        if (!baseUrl) {
          setStatus("Keine laufende Instanz gefunden.", true);
          return;
        }
        if (baseUrlInput) {
          baseUrlInput.value = baseUrl;
        }
        setStatus(`base_url gesetzt: ${baseUrl}`);
      } catch (error) {
        setStatus(error.message, true);
      }
    });
  })();
</script>
{% endblock %}
